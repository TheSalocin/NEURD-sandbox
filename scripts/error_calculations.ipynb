{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skeletonization\n",
    "\n",
    "This notebook contains code to skeletonize segmentations and calculate ERL, number of merge errors and number of split errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import kimimaro\n",
    "import h5py\n",
    "from cloudvolume import Skeleton\n",
    "from glob import glob\n",
    "from zmesh import Mesher\n",
    "import trimesh\n",
    "import skeletor as sk\n",
    "\n",
    "# Works due to changes in .py files directly (from em_util.io import seg_relabel -> from em_util.em_util.io import seg_relabel)\n",
    "# and because em_util in same folder\n",
    "from em_erl.erl import skel_to_erlgraph\n",
    "from em_erl.eval import compute_erl_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stolen from PytorchConnectomics/em_erl\n",
    "# https://github.com/PytorchConnectomics/em_erl/blob/main/em_erl/eval.py\n",
    "def compute_segment_lut(\n",
    "    segment, node_position, mask=None, chunk_num=1, data_type=np.uint32\n",
    "):\n",
    "    \"\"\"\n",
    "    The function `compute_segment_lut` is a low memory version of a lookup table\n",
    "    computation for node segments in a 3D volume.\n",
    "\n",
    "    :param node_position: A numpy array containing the coordinates of each node. The shape of the array\n",
    "    is (N, 3), where N is the number of nodes and each row represents the (z, y, x) coordinates of a\n",
    "    node\n",
    "    :param segment: either a 3D volume or a string representing the\n",
    "    name of a file containing segment data.\n",
    "    :param chunk_num: The parameter `chunk_num` is the number of chunks into which the volume is divided\n",
    "    for reading. It is used in the `read_vol` function to specify which chunk to read, defaults to 1\n",
    "    (optional)\n",
    "    :param data_type: The parameter `data_type` is the data type of the array used to store the node segment\n",
    "    lookup table. In this case, it is set to `np.uint32`, which means the array will store unsigned\n",
    "    32-bit integers\n",
    "    :return: a list of numpy arrays, where each array represents the node segment lookup table for a\n",
    "    specific segment.\n",
    "    \"\"\"\n",
    "    if not isinstance(segment, str):\n",
    "        # load the whole segment\n",
    "        node_lut = segment[\n",
    "            node_position[:, 0], node_position[:, 1], node_position[:, 2]\n",
    "        ]\n",
    "        mask_id = []\n",
    "        if mask is not None:\n",
    "            if isinstance(mask, str):\n",
    "                mask = read_vol(mask)\n",
    "            mask_id = segment[mask > 0]\n",
    "    else:\n",
    "        # read segment by chunk (when memory is limited)\n",
    "        assert \".h5\" in segment\n",
    "        node_lut = np.zeros(node_position.shape[0], data_type)\n",
    "        mask_id = [[]] * chunk_num\n",
    "        start_z = 0\n",
    "        for chunk_id in range(chunk_num):\n",
    "            seg = read_vol(segment, None, chunk_id, chunk_num)\n",
    "            last_z = start_z + seg.shape[0]\n",
    "            ind = (node_position[:, 0] >= start_z) * (node_position[:, 0] < last_z)\n",
    "            pts = node_position[ind]\n",
    "            node_lut[ind] = seg[pts[:, 0] - start_z, pts[:, 1], pts[:, 2]]\n",
    "            if mask is not None:\n",
    "                if isinstance(mask, str):\n",
    "                    mask_z = read_vol(mask, None, chunk_id, chunk_num)\n",
    "                else:\n",
    "                    mask_z = mask[start_z:last_z]\n",
    "                mask_id[chunk_id] = seg[mask_z > 0]\n",
    "            start_z = last_z\n",
    "        if mask is not None:\n",
    "            # remove irrelevant seg ids (not used by nodes)\n",
    "            node_lut_unique = np.unique(node_lut)\n",
    "            for chunk_id in range(chunk_num):\n",
    "                mask_id[chunk_id] = mask_id[chunk_id][\n",
    "                    np.in1d(mask_id[chunk_id], node_lut_unique)\n",
    "                ]\n",
    "        mask_id = np.concatenate(mask_id)\n",
    "    return node_lut, mask_id\n",
    "\n",
    "# Analogous function for meshes\n",
    "def compute_mesh_lut(\n",
    "    meshes, node_position, anisotropy=(4, 4, 40), data_type=np.uint32\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute lookup table for node segments in a 3D volume of meshes.\n",
    "\n",
    "    :param meshes: A dictionary of trimesh mesh objects, eah with a unique mesh id.\n",
    "    :param node_position: A numpy array containing the coordinates of each node. The shape of the array\n",
    "    is (N, 3), where N is the number of nodes and each row represents the (z, y, x) coordinates of a\n",
    "    node\n",
    "    :param anisotropy: Voxel anisotropy of original volume. Used to scale mesh positions.\n",
    "    :param data_type: The parameter `data_type` is the data type of the array used to store the node segment\n",
    "    lookup table. In this case, it is set to `np.uint32`, which means the array will store unsigned\n",
    "    32-bit integers.\n",
    "\n",
    "    :return: a list of numpy arrays, where each array represents the node segment lookup table for a\n",
    "    specific segment.\n",
    "    \"\"\"\n",
    "\n",
    "    scaling_factor = (1/anisotropy[0], 1/anisotropy[1], 1/anisotropy[2])\n",
    "\n",
    "    node_lut = np.zeros(node_position.shape[0], dtype=data_type)\n",
    "    for mesh_id in meshes:\n",
    "        mesh = meshes[mesh_id]\n",
    "        mesh.apply_scale(scaling_factor)\n",
    "\n",
    "        contains = mesh.contains(node_position)\n",
    "        node_lut[contains] = mesh_id\n",
    "\n",
    "    return node_lut\n",
    "\n",
    "\n",
    "# For Microns data\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Helper function to load all npy and npz files in a directory into a single numpy array.\n",
    "    Requires all files to have the same shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        The path to the directory containing the npy and npz files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A numpy array containing the loaded data.\n",
    "    \"\"\"\n",
    "    files = sorted(glob(path + \"*.npy\"))\n",
    "\n",
    "    data_shape = np.load(files[0]).shape\n",
    "\n",
    "    out = np.zeros((data_shape[0], data_shape[1], len(files)))\n",
    "\n",
    "    for i, f in enumerate(files):\n",
    "        out[:, :, i] = np.load(f)\n",
    "\n",
    "    return out.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For FFN Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results from ffn segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('data/fib25_results/fib25/training2/0/0/seg-0_0_0.npz') as data:\n",
    "    segmentation = data['segmentation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling Holes: 100%|██████████| 3982/3982 [00:02<00:00, 1766.52it/s]\n",
      "Fixing Avocados: 100%|██████████| 3/3 [00:00<00:00,  6.53it/s]\n",
      "Avocado Pass:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Skeletonizing Labels: 100%|██████████| 251/251 [00:52<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "skels = kimimaro.skeletonize(\n",
    "  segmentation, \n",
    "  teasar_params={\n",
    "    \"scale\": 1.5, \n",
    "    \"const\": 300, # physical units\n",
    "    \"pdrf_scale\": 100000,\n",
    "    \"pdrf_exponent\": 4,\n",
    "    \"soma_acceptance_threshold\": 3500, # physical units\n",
    "    \"soma_detection_threshold\": 750, # physical units\n",
    "    \"soma_invalidation_const\": 300, # physical units\n",
    "    \"soma_invalidation_scale\": 2,\n",
    "    \"max_paths\": 300, # default None\n",
    "  },\n",
    "  # object_ids=[ ... ], # process only the specified labels\n",
    "  # extra_targets_before=[ (27,33,100), (44,45,46) ], # target points in voxels\n",
    "  # extra_targets_after=[ (27,33,100), (44,45,46) ], # target points in voxels\n",
    "  dust_threshold=1000, # skip connected components with fewer than this many voxels\n",
    "  anisotropy=(10,10,10), # default True\n",
    "  fix_branching=True, # default True\n",
    "  fix_borders=True, # default True\n",
    "  fill_holes=True, # default False\n",
    "  fix_avocados=True, # default False\n",
    "  progress=True, # default False, show progress bar\n",
    "  parallel=1, # <= 0 all cpu, 1 single process, 2+ multiprocess\n",
    "  parallel_chunk_size=100, # how many skeletons to process before updating progress bar\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ground truth segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/fib25_results/flyEM/groundtruth.h5', 'r') as f:\n",
    "    gt_seg = np.array(f['stack'])\n",
    "    transforms = np.array(f['transforms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling Holes: 100%|██████████| 36726/36726 [00:00<00:00, 48573.01it/s]\n",
      "Avocado Pass:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Skeletonizing Labels: 100%|██████████| 2745/2745 [00:28<00:00, 97.95it/s] \n"
     ]
    }
   ],
   "source": [
    "gt_skels = kimimaro.skeletonize(\n",
    "  gt_seg, \n",
    "  teasar_params={\n",
    "    \"scale\": 1.5, \n",
    "    \"const\": 300, # physical units\n",
    "    \"pdrf_scale\": 100000,\n",
    "    \"pdrf_exponent\": 4,\n",
    "    \"soma_acceptance_threshold\": 3500, # physical units\n",
    "    \"soma_detection_threshold\": 750, # physical units\n",
    "    \"soma_invalidation_const\": 300, # physical units\n",
    "    \"soma_invalidation_scale\": 2,\n",
    "    \"max_paths\": 300, # default None\n",
    "  },\n",
    "  # object_ids=[ ... ], # process only the specified labels\n",
    "  # extra_targets_before=[ (27,33,100), (44,45,46) ], # target points in voxels\n",
    "  # extra_targets_after=[ (27,33,100), (44,45,46) ], # target points in voxels\n",
    "  dust_threshold=1000, # skip connected components with fewer than this many voxels\n",
    "  anisotropy=(10,10,10), # default True\n",
    "  fix_branching=True, # default True\n",
    "  fix_borders=True, # default True\n",
    "  fill_holes=True, # default False\n",
    "  fix_avocados=True, # default False\n",
    "  progress=True, # default False, show progress bar\n",
    "  parallel=1, # <= 0 all cpu, 1 single process, 2+ multiprocess\n",
    "  parallel_chunk_size=100, # how many skeletons to process before updating progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Run Length calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get erl score from em_erl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gt graph from gt skeleton\n",
    "gt_graph = skel_to_erlgraph(gt_skels)\n",
    "\n",
    "# get predicted graph from predicted skeletons\n",
    "pred_graph = skel_to_erlgraph(skels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get positions of nodes in coordinates with voxel size (10,10,10)\n",
    "node_position = pred_graph.get_nodes_position((10,10,10))\n",
    "\n",
    "gt_node_position = gt_graph.get_nodes_position((10,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute segment lookup-table. For each skeleton node, which segment of ground truth would it belong to\n",
    "node_segment_lut, mask_segment_id = compute_segment_lut(gt_seg, node_position, None)\n",
    "\n",
    "gt_node_segment_lut, gt_mask_segment_id = compute_segment_lut(gt_seg, gt_node_position, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all skel\n",
      "ERL\t: 1.63\n",
      "gt ERL\t: 7539.24\n",
      "#skel\t: 249\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate score\n",
    "score = compute_erl_score(erl_graph=pred_graph,\n",
    "    node_segment_lut=node_segment_lut,\n",
    "    mask_segment_id=mask_segment_id,\n",
    "    merge_threshold=0,\n",
    "    verbose=True)\n",
    "\n",
    "score.compute_erl(None)\n",
    "\n",
    "score.print_erl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all skel\n",
      "ERL\t: 5709.76\n",
      "gt ERL\t: 5709.76\n",
      "#skel\t: 2327\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Compare with score for ground truth compared to itself for checking\n",
    "gt_score = compute_erl_score(erl_graph=gt_graph,\n",
    "    node_segment_lut=gt_node_segment_lut,\n",
    "    mask_segment_id=gt_mask_segment_id,\n",
    "    merge_threshold=0,\n",
    "    verbose=True)\n",
    "\n",
    "gt_score.compute_erl(None)\n",
    "gt_score.print_erl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, erl is computed but shows that segmentation is trash. This doesn't fit expectations as visually, segmentation seemed ok. My guess is that there is an issue in the data format for ground truth segmentation: When examining data in playground.ipynb, slicing across z gives good results for both prediction and gt, but slicing through y or x gives only good results for prediction. In some way, ground truth segmentation is not aligned with raw image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Microns Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_seg = load_data(\"data/microns/seg_v1078/\")\n",
    "\n",
    "# Some procesing to reduce memory usage\n",
    "gt_seg = gt_seg - (np.min(gt_seg[np.nonzero(gt_seg)]) - 1)\n",
    "gt_seg = gt_seg.astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling Holes: 100%|██████████| 1061/1061 [00:02<00:00, 439.11it/s]\n",
      "Fixing Avocados: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "Avocado Pass:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Skeletonizing Labels: 100%|██████████| 602/602 [01:38<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "gt_skels = kimimaro.skeletonize(\n",
    "        gt_seg, \n",
    "        teasar_params={\n",
    "            \"scale\": 1.5, \n",
    "            \"const\": 300, # physical units\n",
    "            \"pdrf_scale\": 100000,\n",
    "            \"pdrf_exponent\": 4,\n",
    "            \"soma_acceptance_threshold\": 3500, # physical units\n",
    "            \"soma_detection_threshold\": 750, # physical units\n",
    "            \"soma_invalidation_const\": 300, # physical units\n",
    "            \"soma_invalidation_scale\": 2,\n",
    "            \"max_paths\": 300, # default None\n",
    "        },\n",
    "        dust_threshold=1000, # skip connected components with fewer than this many voxels\n",
    "        anisotropy=(4,4,40), # default True\n",
    "        fix_branching=True, # default True\n",
    "        fix_borders=True, # default True\n",
    "        fill_holes=True, # default False\n",
    "        fix_avocados=True, # default False\n",
    "        progress=True, # default False, show progress bar\n",
    "        parallel=1, # <= 0 all cpu, 1 single process, 2+ multiprocess\n",
    "        parallel_chunk_size=100, # how many skeletons to process before updating progress bar\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earlier unproofread Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_seg = load_data('data/microns/seg_v117/')\n",
    "\n",
    "# Some procesing to reduce memory usage\n",
    "old_seg = old_seg - (np.min(old_seg[np.nonzero(old_seg)]) - 1)\n",
    "old_seg = old_seg.astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling Holes: 100%|██████████| 1061/1061 [00:02<00:00, 440.07it/s]\n",
      "Fixing Avocados: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
      "Avocado Pass:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Skeletonizing Labels: 100%|██████████| 602/602 [01:35<00:00,  6.29it/s]\n"
     ]
    }
   ],
   "source": [
    "old_skels = kimimaro.skeletonize(\n",
    "        old_seg, \n",
    "        teasar_params={\n",
    "            \"scale\": 1.5, \n",
    "            \"const\": 300, # physical units\n",
    "            \"pdrf_scale\": 100000,\n",
    "            \"pdrf_exponent\": 4,\n",
    "            \"soma_acceptance_threshold\": 3500, # physical units\n",
    "            \"soma_detection_threshold\": 750, # physical units\n",
    "            \"soma_invalidation_const\": 300, # physical units\n",
    "            \"soma_invalidation_scale\": 2,\n",
    "            \"max_paths\": 300, # default None\n",
    "        },\n",
    "        dust_threshold=1000, # skip connected components with fewer than this many voxels\n",
    "        anisotropy=(4, 4, 40), # default True\n",
    "        fix_branching=True, # default True\n",
    "        fix_borders=True, # default True\n",
    "        fill_holes=True, # default False\n",
    "        fix_avocados=True, # default False\n",
    "        progress=True, # default False, show progress bar\n",
    "        parallel=1, # <= 0 all cpu, 1 single process, 2+ multiprocess\n",
    "        parallel_chunk_size=100, # how many skeletons to process before updating progress bar\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_graph = skel_to_erlgraph(gt_skels)\n",
    "proof_graph = skel_to_erlgraph(old_skels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_position = proof_graph.get_nodes_position((4, 4, 40))\n",
    "\n",
    "node_segment_lut, mask_segment_id = compute_segment_lut(gt_seg, nodes_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all skel\n",
      "ERL\t: 11977.55\n",
      "gt ERL\t: 12036.00\n",
      "#skel\t: 484\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "score = compute_erl_score(erl_graph=proof_graph,\n",
    "    node_segment_lut=node_segment_lut,\n",
    "    mask_segment_id=mask_segment_id,\n",
    "    merge_threshold=0,\n",
    "    verbose=True)\n",
    "\n",
    "score.compute_erl(None)\n",
    "score.print_erl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3403396225, 3403396225, 3403396225, ..., 3186486657, 3186486657,\n",
       "       3186486657], dtype=uint32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_segment_lut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ERL for meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make meshes from segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mesher for voxel size (4, 4, 40) [(x, y, z)]\n",
    "old_mesher = Mesher((4,4,40))\n",
    "old_mesher.mesh(old_seg, close=True)\n",
    "\n",
    "# Extract meshes for further processing\n",
    "old_meshes = dict()\n",
    "for obj_id in old_mesher.ids():\n",
    "  mesh = old_mesher.get(\n",
    "      obj_id, \n",
    "      normals=False, # whether to calculate normals or not\n",
    "      # No simplification, so that lookup table is more accurate\n",
    "      reduction_factor=0,\n",
    "\n",
    "      # max_errors and voxel_centered may improve lut calculation\n",
    "\n",
    "      # Max tolerable error in physical distance\n",
    "      # note: if max_error is not set, the max error\n",
    "      # will be set equivalent to one voxel along the \n",
    "      # smallest dimension.\n",
    "      max_error=8,\n",
    "      # whether meshes should be centered in the voxel\n",
    "      # on (0,0,0) [False] or (0.5,0.5,0.5) [True]\n",
    "      voxel_centered=False, \n",
    "    )\n",
    "  # Transform to trimesh object\n",
    "  old_meshes[obj_id] = trimesh.Trimesh(vertices=mesh.vertices, faces=mesh.faces)\n",
    "  # Free up memory\n",
    "  old_mesher.erase(obj_id)\n",
    "  del mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same for gt meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mesher for voxel size (4, 4, 40) [(x, y, z)]\n",
    "gt_mesher = Mesher((4,4,40))\n",
    "gt_mesher.mesh(gt_seg, close=True)\n",
    "\n",
    "\n",
    "gt_meshes = dict()\n",
    "for obj_id in gt_mesher.ids():\n",
    "  mesh = gt_mesher.get(\n",
    "      obj_id, \n",
    "      normals=False, # whether to calculate normals or not\n",
    "\n",
    "      # tries to reduce triangles by this factor\n",
    "      # 0 disables simplification\n",
    "      reduction_factor=0, \n",
    "\n",
    "      # Max tolerable error in physical distance\n",
    "      # note: if max_error is not set, the max error\n",
    "      # will be set equivalent to one voxel along the \n",
    "      # smallest dimension.\n",
    "      max_error=8,\n",
    "      # whether meshes should be centered in the voxel\n",
    "      # on (0,0,0) [False] or (0.5,0.5,0.5) [True]\n",
    "      voxel_centered=False, \n",
    "    )\n",
    "  gt_meshes[obj_id] = trimesh.Trimesh(vertices=mesh.vertices, faces=mesh.faces)\n",
    "  # Free up memory\n",
    "  gt_mesher.erase(obj_id) # delete high res mesh\n",
    "  del mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_lut = compute_mesh_lut(gt_meshes, nodes_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8652134693535938"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate overlap between mesh lut and segmentation lut\n",
    "(mesh_lut == node_segment_lut).sum()/mesh_lut.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all skel\n",
      "ERL\t: 3.07\n",
      "gt ERL\t: 12043.16\n",
      "#skel\t: 484\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Mask segment ID is not currently implemented with mesh lut\n",
    "score = compute_erl_score(erl_graph=gt_graph,\n",
    "    node_segment_lut=mesh_lut,\n",
    "    mask_segment_id=[],\n",
    "    merge_threshold=0,\n",
    "    verbose=True)\n",
    "\n",
    "score.compute_erl(None)\n",
    "score.print_erl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate number of merges/splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkelab implementation\n",
    "\n",
    "# get unique segments of gt_graph\n",
    "skeleton_segment, count = np.unique(\n",
    "        np.hstack([gt_graph.nodes[:, :1], node_segment_lut.reshape(-1, 1)]),\n",
    "        axis=0,\n",
    "        return_counts=True,\n",
    "    )\n",
    "\n",
    "# how many skeletons are in each gt segment\n",
    "segments, num_segment_skeletons = np.unique(\n",
    "        skeleton_segment[:, 1], \n",
    "        return_counts=True\n",
    "    )\n",
    "\n",
    "merges = {}\n",
    "# segments with merge errors have more than one gt skeleton assigned\n",
    "merging_segments = segments[num_segment_skeletons > 1]\n",
    "# keep those segments that merge\n",
    "merging_segments_mask = np.isin(skeleton_segment[:, 1], merging_segments)\n",
    "merged_segments = skeleton_segment[:, 1][merging_segments_mask]\n",
    "\n",
    "merged_skeletons = skeleton_segment[:, 0][merging_segments_mask]\n",
    "\n",
    "# collect ids of segments that are merged together\n",
    "for segment, skeleton in zip(merged_segments, merged_skeletons):\n",
    "    if segment not in merges:\n",
    "        merges[segment] = []\n",
    "    merges[segment].append(skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {}\n",
    "n_splits = 0\n",
    "for skeleton_id in old_skels:\n",
    "    \n",
    "    skeletons = old_skels[skeleton_id]\n",
    "    \n",
    "    # for coordinates of each edge, collect which segment they are assigned to\n",
    "    for u, v in skeletons.edges:\n",
    "        segment_u = node_segment_lut[u]\n",
    "        segment_v = node_segment_lut[v]\n",
    "\n",
    "    # if the edges are not both assigned to the same segment, there is a split error\n",
    "    if segment_u != segment_v:\n",
    "        n_splits += 1\n",
    "\n",
    "        # collect which segment was split to which ids\n",
    "        if skeleton_id not in splits:\n",
    "            splits[skeleton_id] = []\n",
    "        splits[skeleton_id].append((segment_u, segment_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Mergers and Splits, return number of problematic skeletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformulation of above code to collect all problematic segments that require human proofreading\n",
    "\n",
    "problem_segments = []\n",
    "n_merges = 0\n",
    "n_splits = 0\n",
    "\n",
    "\n",
    "# Mergers\n",
    "# TODO: why different number of mergers than funkelab implementation?\n",
    "skeleton_segment, count = np.unique(\n",
    "        np.hstack([gt_graph.nodes[:, :1], node_segment_lut.reshape(-1, 1)]),\n",
    "        axis=0,\n",
    "        return_counts=True,\n",
    "    )\n",
    "segments, num_segment_skeletons = np.unique(\n",
    "        skeleton_segment[:, 1], return_counts=True\n",
    "    )\n",
    "\n",
    "merged_segments = segments[num_segment_skeletons > 1]\n",
    "merging_segments_mask = np.isin(skeleton_segment[:, 1], merged_segments)\n",
    "\n",
    "merged_segments = skeleton_segment[:, 1][merging_segments_mask]\n",
    "\n",
    "merged_skeletons = np.unique(\n",
    "    skeleton_segment[np.isin(skeleton_segment[:, 1], merged_segments), 0]\n",
    ")\n",
    "\n",
    "n_mergers = len(merged_segments)\n",
    "\n",
    "problem_segments += list(merged_segments)\n",
    "\n",
    "\n",
    "# Splits TODO: probably inefficient\n",
    "for skeleton_id in proof_skels:\n",
    "    \n",
    "    skeletons = proof_skels[skeleton_id]\n",
    "    \n",
    "    for u, v in skeletons.edges:\n",
    "        segment_u = node_segment_lut[u]\n",
    "        segment_v = node_segment_lut[v]\n",
    "\n",
    "    if segment_u != segment_v:\n",
    "        n_splits += 1\n",
    "\n",
    "        if skeleton_id not in problem_segments:\n",
    "            problem_segments += [skeleton_id]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
